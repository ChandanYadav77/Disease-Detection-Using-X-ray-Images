# -*- coding: utf-8 -*-
"""DS_MARKsequential .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yurd5vn9wvEGMAcnCRBJ_SWr7mSmAS-R
"""

import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models, callbacks
import matplotlib.pyplot as plt

import kagglehub

# Download latest version
path = kagglehub.dataset_download("prashant268/chest-xray-covid19-pneumonia")

print("Path to dataset files:", path)

import kagglehub

# Download latest version
path = kagglehub.dataset_download("tawsifurrahman/tuberculosis-tb-chest-xray-dataset")

print("Path to dataset files:", path)

# Paths to data
data_dir = "/root/.cache/kagglehub/datasets/prashant268/chest-xray-covid19-pneumonia/versions/2/Data/train"  # Replace with your dataset path

# Hyperparameters
image_size = (150, 150)
batch_size = 32
epochs = 30

# Data augmentation and preprocessing
datagen = ImageDataGenerator(
    rescale=1.0 / 255,  # Normalize pixel values
    rotation_range=20,  # Randomly rotate images
    width_shift_range=0.2,  # Randomly shift images horizontally
    height_shift_range=0.2,  # Randomly shift images vertically
    shear_range=0.2,  # Shear transformation
    zoom_range=0.2,  # Zoom-in/out
    horizontal_flip=True,  # Randomly flip images horizontally
    validation_split=0.2  # Split dataset into training and validation sets
)

# Training data generator
train_generator = datagen.flow_from_directory(
    data_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

# Validation data generator
validation_generator = datagen.flow_from_directory(
    data_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# Map class indices to class labels
class_indices = train_generator.class_indices
print("Class Indices:", class_indices)

# Count the number of images per class in the training set
train_class_counts = {class_name: list(train_generator.classes).count(idx)
                      for class_name, idx in train_generator.class_indices.items()}
print("Training Class Counts:", train_class_counts)

# Count the number of images per class in the validation set
validation_class_counts = {class_name: list(validation_generator.classes).count(idx)
                           for class_name, idx in validation_generator.class_indices.items()}
print("Validation Class Counts:", validation_class_counts)

# Define CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),  # Prevent overfitting
    layers.Dense(4, activation='softmax')  # Output layer for 4 classes
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Print model summary
model.summary()

# Early stopping to prevent overfitting
early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Model checkpoint to save the best model
checkpoint = callbacks.ModelCheckpoint(
    'best_model.keras',
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

# Train the model
history = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=validation_generator,
    callbacks=[early_stopping, checkpoint]
)

# Evaluate model on validation data
# from tensorflow.keras.models import load_model

# # Correct the path to your uploaded model
# model = load_model('/content/trained_model.keras')

val_loss, val_accuracy = model.evaluate(validation_generator)
print(f"Validation Loss: {val_loss}")
print(f"Validation Accuracy: {val_accuracy}")
##### sequential
# model.summary()

# Plot accuracy
plt.figure(figsize=(8, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot loss
plt.figure(figsize=(8, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

model.save('/content/trained_model.keras')  # Save in native Keras format
# if os.path.exists('/content/trained_model.keras'):
#     print("Model saved at: /content/trained_model.keras")
# else:
#     print("Model not found.")

from tensorflow.keras.preprocessing import image
import numpy as np

def predict_image(img_path, model, class_indices):
    img = image.load_img(img_path, target_size=image_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize

    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions)
    class_labels = {v: k for k, v in class_indices.items()}
    return class_labels[predicted_class], predictions

# Example prediction
test_image_path = "/root/.cache/kagglehub/datasets/prashant268/chest-xray-covid19-pneumonia/versions/2/Data/test/PNEUMONIA/PNEUMONIA(3420).jpg"  # Replace with the path to your test image
predicted_label, prediction_probs = predict_image(test_image_path, model, class_indices)
print(f"Predicted Class: {predicted_label}")
print(f"Prediction Probabilities: {prediction_probs}")

# Get predictions for the validation data
y_pred_prob = model.predict(validation_generator)
y_pred = np.argmax(y_pred_prob, axis=1)

# Get true labels for the validation data
y_true = validation_generator.classes

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Generate the confusion matrix
cm = confusion_matrix(x_true, x_pred)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

#Evaluate model on validation data
from tensorflow.keras.models import load_model

# Correct the path to your uploaded model
model = load_model('/content/trained_model.keras')

val_loss, val_accuracy = model.evaluate(validation_generator)
print(f"Validation Loss: {val_loss}")
print(f"Validation Accuracy: {val_accuracy}")

# model.summary()

# Get predictions for the validation data
import numpy as np
y_pred_prob = model.predict(validation_generator)
y_pred = np.argmax(y_pred_prob, axis=1)

# Get true labels for the validation data
y_true = validation_generator.classes

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Generate the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()



